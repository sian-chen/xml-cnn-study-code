# data
data_dir: data/Amazon-670K
data_name: Amazon-670K
min_vocab_freq: 1
max_seq_length: 500
train_path: data/Amazon-670K/train_rv.txt
test_path: data/Amazon-670K/test_rv.txt

# train
seed: 1337
epochs: 50
batch_size: 64
optimizer: adam
learning_rate: 0.0001
weight_decay: 0
patience: 5
shuffle: true

# eval
eval_batch_size: 256
monitor_metrics: [P@1, P@3, P@5, nDCG@1, nDCG@3, nDCG@5]
val_metric: P@1

# model
model_name: KimCNNv2
num_filter_per_size: 768 # filter channels
filter_sizes: [8]
dropout: 0.6
dropout2: 0.2
init_weight: kaiming_uniform
activation: relu

# pretrained vocab / embeddings
embed_file: glove.6B.300d
vocab_file: null

# other parameters specified in main.py::get_args
cpu: false
data_workers: 4
display_iter: 100
eval: false
fixed_length: false
label_file: null
load_checkpoint: null
metrics_thresholds: [0.5]
momentum: 0.9
predict_out_path: null
result_dir: runs
val_path: null
use_extended_loss: true
val_size: 0
