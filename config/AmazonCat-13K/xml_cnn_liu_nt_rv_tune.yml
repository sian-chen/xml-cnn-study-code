# data
data_dir: data/AmazonCat-13K
data_name: AmazonCat-13K
min_vocab_freq: 1
max_seq_length: 500
fixed_length: True
shuffle: True
train_path: data/AmazonCat-13K/train_rv.txt
test_path: data/AmazonCat-13K/test_rv.txt
val_size: 0.2

# train
seed: null
epochs: 50
batch_size: 256
optimizer: adam
learning_rate: ['choice', [0.0003, 0.001, 0.003]]
weight_decay: 0
patience: 5

# eval
eval_batch_size: 256
monitor_metrics: [P@1, P@3, P@5]
val_metric: P@1

# model
model_name: XMLCNNLiu
num_filter_per_size: ['choice', [256, 128, 64]] # filter channels
filter_sizes: [2, 4, 8]
conv_stride: 2
num_pool: 1
pool_size: 2
dropout: ['choice', [0, 0.25, 0.5]]
hidden_dim: ['choice', [1024, 512, 256]]
dropout2: ['choice', [0.25, 0.5, 0.75]]
init_weight: xavier_uniform
activation: relu
no_transpose: true

# pretrained vocab / embeddings
embed_file: glove.6B.300d
vocab_file: null

# hyperparamter search
search_alg: optuna
embed_cache_dir: .vector_cache

# other parameters specified in main.py::get_args
config: config/AmazonCat-13K/xml_cnn_liu_nt_rv_tune.yml
cpu: false
data_workers: 4
display_iter: 100
eval: false
label_file: null
load_checkpoint: null
metrics_thresholds: [0.5]
momentum: 0.9
predict_out_path: null
result_dir: runs
silent: true
val_path: null
val_size: 0.2
use_extended_loss: false
eval_last: false
